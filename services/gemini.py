import os

import google.generativeai as genai
from dotenv import load_dotenv

load_dotenv()

# create api_key variable
api_key = os.getenv("GEMINI_API_KEY")
# Initialize the Gemini API client

genai.configure(api_key=api_key)

# crear variable para el modelo
model = genai.GenerativeModel(model_name="gemini-1.5-pro", generation_config=genai.GenerationConfig(
    temperature=0.5,
    max_output_tokens=256,
    top_p=0.95,
    top_k=40
))

"""
    - top_p (float): Controla la "nucleus sampling" o muestreo de n칰cleo. 
    Este par치metro especifica el umbral de probabilidad acumulada para considerar 
    las siguientes palabras candidatas en la generaci칩n de texto. Por ejemplo,
    si top_p=0.95, el modelo seleccionar치 palabras de entre el conjunto m치s peque침o posible
    cuyo total de probabilidades sume al menos el 95%. Esto ayuda a mantener la diversidad 
    en las respuestas, evitando que el modelo elija siempre las palabras m치s probables.

    - top_k (int): Limita el n칰mero de palabras candidatas consideradas en cada paso de generaci칩n. 
    Si top_k=40, el modelo solo considerar치 las 40 palabras m치s probables para seleccionar la
    siguiente palabra en la secuencia. Un valor m치s bajo hace que las respuestas sean m치s predecibles, 
    mientras que un valor m치s alto permite mayor diversidad.

"""


def ask_gemini(prompt:str) -> str:
    """
    Funcion base para interactuar con gemini """
    response = model.generate_content(prompt)
    print("游 Prompt generado:\n", prompt)
    return response.text.strip() if response.text else "Gemini no pudo generar una respuesta."